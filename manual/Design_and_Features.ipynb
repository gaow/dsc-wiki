{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Overview\n",
    "DSC2 is designed to manage and execute all computations required for *Dynamic Statistical Comparisons*. Typically such comparisons involve generating (or gathering) data, performing statistical analyses and evaluating performance of statistical procedures applied. Each step takes some input data from previous step (unless it is the first step) and create some output to be passed to the next step, or to be interpreted as the outcome of the DSC. A DSC user thus has two jobs: define computational steps (as [DSC modules](Terminology.html)), and specify how the steps are connected to be executed (as [DSC pipelines](Terminology.html)).\n",
    "\n",
    "As a first pass to illustrating the DSC design, let's consider a DSC sequence consists of 3 types of steps: **scenarios**, **methods** and **scores**, where\n",
    "\n",
    "*  **scenarios**: provide input data and / or configures computational routines that generate input data.\n",
    "*  **methods**: defines statistical procedures that analyzes data.\n",
    "*  **scores**: defines methods that evaluates the result of data analyses compared to the \"truth\" (model from which the data is generated) and calculates scores that measures performance of methods.\n",
    "\n",
    "In practice DSC is more generic and flexible -- one does not have to follow this paradigm when composing a DSC, as long as steps and sequences are properly defined. You may often have incomplete DSC in the exploratory phase of a project as you develop methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below follows the aforementioned 3 steps paradigm but we will allow for combinations of computational steps as illustrated in pipelines below,\n",
    "\n",
    "**FIXME: to be replaced by an Adobe Illustrator figure**\n",
    "\n",
    "```\n",
    "  | scenario 1               |    | method 1 ->                      |    | score 1 |\n",
    "  | scenario 2               | -> | method 2 -> method 1             | -> | score 2 |\n",
    "  | scenario 1 -> scenario 3 |    | method 3 -> method 2 -> method 1 |    | ...     |\n",
    "  | scenario 4 -> ...        |    | method 4 -> ...                  |    | ...     |\n",
    "```\n",
    "\n",
    "where each **scenario**, **method** and **score** is a computational step which can be different approaches to generate data, perform statistical analysis, or measure performance of methods, or can be the same approaches with different parameter settings. The arrows connects the computational steps into sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Case Study\n",
    "\n",
    "To understand the DSC design we review a simple example with (mostly) self-explanatory syntax. DSC syntax is completely documented [elsewhere](DSC_Configuration.html); readers should not worry about learning the syntax at this point.\n",
    "\n",
    "In this example we compare methods of estimating location parameter from data. We use data generated from *t* distribution and Cauchy distribution, remove outliers (with two Winsorization methods) and estimate mean (via sample average or median), and evaluate performance of sequences of these steps by comparing the estimate with the \"ground truth\" in terms of mean squared error. \n",
    "\n",
    "### DSC script\n",
    "\n",
    "```\n",
    "t, cauchy: rt.R, rcauchy.R\n",
    " replicate: R(1:5)\n",
    " n: 1000\n",
    " true_loc: 0, 1\n",
    " $x: x\n",
    " $true_loc: true_loc\n",
    "\n",
    "winsor1, winsor2: winsor1.R, winsor2.R\n",
    " x: $x\n",
    " @winsor1:\n",
    "     fraction: 0.05\n",
    " @winsor2:\n",
    "     multiple: 3\n",
    " $x: x\n",
    "\n",
    "mean, median: mean.R, median.R\n",
    "  x: $x\n",
    "  $loc: loc\n",
    "\n",
    "mse: mse.R\n",
    "  mean_est: $loc\n",
    "  true_mean: $true_loc\n",
    "  $mse: mse\n",
    "\n",
    "DSC:\n",
    "  define: \n",
    "      simulate: t, cauchy\n",
    "      transform: winsor1, winsor2\n",
    "      estimate: mean, median\n",
    "      score: mse\n",
    "  run: simulate *\n",
    "       (transform * estimate, estimate) *\n",
    "       score\n",
    "  exec_path: R\n",
    "  output: dsc_result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSC execution\n",
    "The sequence to execute:\n",
    "```\n",
    "      run: simulate *\n",
    "           (transform * estimate, estimate) *\n",
    "           score\n",
    "```\n",
    "will be expanded to 2 sequences:\n",
    "\n",
    "1. `simulate -> transform -> estimate -> score`\n",
    "2. `simulate -> estimate -> score`\n",
    "\n",
    "Or 12 sequences in terms of computational executables \n",
    "\n",
    "1. `rt.R -> winsor1.R -> mean.R -> mse.R`\n",
    "2. `rt.R -> winsor1.R -> median.R -> mse.R`\n",
    "3. `rt.R -> winsor2.R -> mean.R -> mse.R`\n",
    "4. `rt.R -> winsor2.R -> median.R -> mse.R`\n",
    "5. `rcauchy.R -> winsor1.R -> mean.R -> mse.R`\n",
    "6. `rcauchy.R -> winsor1.R -> median.R -> mse.R`\n",
    "7. `rcauchy.R -> winsor2.R -> mean.R -> mse.R`\n",
    "8. `rcauchy.R -> winsor2.R -> median.R -> mse.R`\n",
    "9. `rt.R -> mean.R -> mse.R`\n",
    "10. `rt.R -> median.R -> mse.R`\n",
    "11. `rcauchy.R -> mean.R -> mse.R`\n",
    "12. `rcauchy.R -> median.R -> mse.R`\n",
    "\n",
    "By allowing for different parameters to each executable, more combinations are implicitly defined and consequently more unique sequences executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief narrative to the case study\n",
    "\n",
    "As has been previously motivated, there are 3 steps in this example: **scenarios**, **methods** and **scores**.\n",
    "\n",
    "The **scenarios** part is the first code block in the file, which has two computational executables `rcauchy.R` and `rt.R`. These routines generate `n` random samples under Cauchy distribution with location parameter `true_loc`, and *t* distribution with non-centrality parameter `true_loc`, respectively. There are 2 choices of computational routines, each routine has one choice of `n` (1000) and two choices of `true_loc` (0 and 1). 5 replicates are evaluated as defined by `replicate`. As a result, this code block will result in 20 parallel computations.\n",
    "\n",
    "The **methods** part consists of `transform` and `estimate`. `transform` performs two types of winsorization on input data. `estimate` has two computational routines to estimate location parameter, via sample mean (`mean.R`) and median (`median.R`) respectively. There are two types of procedures for **methods**: the first is `transform + estimate` which runs the `transform` family of steps first, then run the `estimate` family after data has been transformed; the second is `estimate` which directly performs parameter estimation with the original data produced by its upstream steps, ie, from the **scenarios** part.\n",
    "\n",
    "The **scores** part is `score`, which has a single computational routine `mse.R` to calculate the mean square error as a summary of comparison between the *true* (`true_mean`) and *estimated* (`mean_est`) location parameters, taking `$true_loc` and `$loc` respectively corresponding to the *output* values from previous steps in **scenarios** and **methods**\n",
    "\n",
    "In this case study, the design of blocks logically follows the **scenarios**, **methods** (pre-processing via `transformation` and analysis via `estimate`), and **scores** paradigm. It does not have to be this way, though: one can even make separated blocks for each computational routine (in this case for every R script) and combine them in the *run* sequence in *DSC* section in a fashion simular to the 12 pipelines expanded from this DSC as shown in the previous section of this document -- it is a decision users has the liberty to make based on style preference and logic. \n",
    "\n",
    "## Output files\n",
    "\n",
    "Computational results and communications throughout DSC will be handled implicitly. Users do not have to worry about file output. Yet users are responsible for matching variables specified in DSC script to what are in fact written in provided computational routines. This is a key feature of DSC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
