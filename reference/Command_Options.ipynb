{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC implements 2 command programs, `dsc` and `dsc-query`, for executing DSC and extracting result from executed benchmarks, respectively.\n",
    "\n",
    "## DSC main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash",
    "output_cache": "[{\"name\":\"stdout\",\"output_type\":\"stream\",\"text\":\"usage: dsc [-h] [--version] [-v {0,1,2,3,4}] [-j N] [-o str] [-f]\\n           [--target str] [-x DSC script] [--sequence str [str ...]]\\n           [--seed values [values ...]] [--recover levels] [--ignore-errors]\\n           [--clean [str [str ...]]] [--host str] [-a file.ann [file.ann ...]]\\n           [-e block:variable [block:variable ...]] [--tags str [str ...]]\\n           [--distribute [files [files ...]]]\\n\\noptional arguments:\\n  -h, --help            show this help message and exit\\n  --version             show program's version number and exit\\n  -v {0,1,2,3,4}, --verbosity {0,1,2,3,4}\\n                        Output error (0), warning (1), info (2), debug (3) and\\n                        trace (4) information. Default to 2.\\n  -j N                  Number of maximum concurrent processes.\\n  -o str                Output data prefix for -x / -e commands.\\n  -f                    Force re-run -x / -e commands from scratch.\\n  --target str          The ultimate target of a DSC benchmark is the name of\\n                        the last block in a DSC sequence. This option is\\n                        relevant to -a / -e commands when there exists\\n                        multiple DSC sequences with different targets.\\n\\nExecute DSC:\\n  -x DSC script, --execute DSC script\\n                        Execute DSC.\\n  --sequence str [str ...]\\n                        DSC sequences to be executed. It will override the\\n                        DSC::run entry when specified. Multiple sequences are\\n                        allowed. Each input should be a quoted string defining\\n                        a valid DSC sequence, or referring to the key of an\\n                        existing sequence in the DSC script. Multiple such\\n                        strings should be separated by space.\\n  --seed values [values ...]\\n                        This will override any \\\"seed\\\" property in the DSC\\n                        script. This feature is useful for using a small\\n                        number of seeds for a test run. Example: `--seed 1`,\\n                        `--seed 1 2 3 4`, `--seed {1..10}`, `--seed \\\"R(1:10)\\\"`\\n  --recover levels      Recover DSC based on names (not contents) of existing\\n                        files. Level 1 recover will try to reconstruct the\\n                        entire benchmark skipping existing files. Level 2\\n                        recover will only use existing files to reconstruct\\n                        the benchmark output metadata, making it possible to\\n                        explore partial benchmark results without having to\\n                        wait until completion of entire benchmark.\\n  --ignore-errors       Bypass all errors from computational programs. This\\n                        will keep the benchmark running but all results will\\n                        be set to missing values and the problematic script\\n                        will be saved when applicable.\\n  --clean [str [str ...]]\\n                        Instead of running DSC, output for one or multiple\\n                        steps from previous DSC runs are to be cleaned. Each\\n                        step should be a valid DSC step in the format of\\n                        \\\"block[index]\\\", or \\\"block\\\" for all steps in the block.\\n                        Multiple steps should be separated by space. When \\\"--\\n                        clean\\\" is used with \\\"-f\\\", all specified files will be\\n                        removed regardless of their step execution status.\\n  --host str            URL of Redis server for distributed computation.\\n\\nAnnotate DSC:\\n  -a file.ann [file.ann ...], --annotate file.ann [file.ann ...]\\n                        Annotate DSC. Annotation files must have \\\".ann\\\"\\n                        extension. If \\\"-a\\\" option is used independently from\\n                        \\\"-x\\\", then the first file should be the DSC\\n                        configuration file with a non-\\\".ann\\\" extension. If\\n                        this rule is violated, the program will attempt to\\n                        look for a file having the same base name as the first\\n                        file but with \\\".dsc\\\" extension and if found it will be\\n                        used as the DSC configuration file.\\n\\nExtract DSC results:\\n  -e block:variable [block:variable ...], --extract block:variable [block:variable ...]\\n                        Variable(s) to extract. Variable(s) should be\\n                        specified by \\\"block:variable\\\". Valid `variable` are\\n                        variables found in `return` of the corresponding DSC\\n                        block.\\n  --tags str [str ...]  Tags to extract. The \\\"&&\\\" sign can be used to specify\\n                        intersect of multiple tags. The \\\"=\\\" sign can be used\\n                        to rename extracted tags. Default to extracting for\\n                        all tags.\\n\\nDistribute DSC:\\n  --distribute [files [files ...]]\\n                        Additional files to distribute. This option will\\n                        create a tarball for the DSC benchmark for\\n                        distribution. If additional files are given to this\\n                        option, then those files will also be included in the\\n                        benchmark.\\n\"}]",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: dsc [--target str [str ...]] [--truncate] [--replicate N] [-o str]\n",
      "           [-s option] [--touch] [--clean option] [-c N] [--ignore-errors]\n",
      "           [-v {0,1,2,3,4}] [--host file] [--to-host dir [dir ...]]\n",
      "           [--version] [-h]\n",
      "           DSC script\n",
      "\n",
      "positional arguments:\n",
      "  DSC script            DSC script to execute.\n",
      "\n",
      "Customized execution:\n",
      "  --target str [str ...]\n",
      "                        This argument can be used in two contexts: 1) When\n",
      "                        used without \"--clean\" it overrides \"DSC::run\" in DSC\n",
      "                        file. Input should be quoted string(s) defining one or\n",
      "                        multiple valid DSC pipelines (multiple pipelines\n",
      "                        should be separated by space). 2) When used along with\n",
      "                        \"--clean\" it specifies one or more computational\n",
      "                        modules, separated by space, whose output are to be\n",
      "                        removed. Alternatively one can specify path(s) of\n",
      "                        particular DSC output files that needs to be removed.\n",
      "                        (default: None)\n",
      "  --truncate            When applied, DSC will only run one value per\n",
      "                        parameter. For example with \"--truncate\", \"n: R(1:50)\"\n",
      "                        will be truncated to \"n: 1\". This is useful in\n",
      "                        exploratory analysis and diagnostics, particularly\n",
      "                        when used in combination with \"--target\". (default:\n",
      "                        False)\n",
      "  --replicate N         Overrides \"DSC::replicate\" to set number of\n",
      "                        replicates. Will be set to 1 when \"--truncate\" is in\n",
      "                        action. (default: None)\n",
      "  -o str                Benchmark output. It overrides \"DSC::output\" defined\n",
      "                        in DSC file. (default: None)\n",
      "\n",
      "Maintenance:\n",
      "  -s option, --skip option\n",
      "                        Behavior of how DSC is executed in the presence of\n",
      "                        existing results. \"default\": skips modules whose\n",
      "                        \"environment\" has not been changed since previous\n",
      "                        execution. \"none\": executes DSC from scratch. \"all\":\n",
      "                        skips all execution yet build DSC database of what the\n",
      "                        specified benchmark is supposed to look like, thus\n",
      "                        making it possible to explore partial benchmark\n",
      "                        results. (default: default)\n",
      "  --touch               \"Touch\" output files if exist, to mark them \"up-to-\n",
      "                        date\". This option is useful when executed benchmark\n",
      "                        files are transferred from one computer to another\n",
      "                        during which file signatures are lost. It will\n",
      "                        override \"--skip\" option. Note that time stamp is\n",
      "                        irrelevant to whether or not a file is up-to-date.\n",
      "                        (default: False)\n",
      "  --clean option        Behavior of how DSC removes files. \"remove\" deletes\n",
      "                        specified files, or files generated by specified\n",
      "                        modules via \"--target\" in current DSC. \"replace\",\n",
      "                        instead of *remove*, will *replace* these files by\n",
      "                        placeholder files with \"*.zapped\" extension, so that\n",
      "                        pipelines involving these files will continue to run\n",
      "                        without regenerating them unless they are directly\n",
      "                        required by another module. This is useful to swap out\n",
      "                        large intermediate files. \"purge\" cleans up obsolete\n",
      "                        outputs in folder \"DSC::output\", after DSC is executed\n",
      "                        with \"-s none\". (default: None)\n",
      "\n",
      "Runtime behavior:\n",
      "  -c N                  Number of maximum cpu threads for local runs, or\n",
      "                        concurrent jobs for remote execution. (default: 4)\n",
      "  --ignore-errors       Bypass all errors from computational programs. This\n",
      "                        will keep the benchmark running but all results will\n",
      "                        be set to missing values and the problematic script\n",
      "                        will be saved when possible. (default: False)\n",
      "  -v {0,1,2,3,4}, --verbosity {0,1,2,3,4}\n",
      "                        Output error (0), warning (1), info (2), debug (3) and\n",
      "                        trace (4) information. (default: 2)\n",
      "\n",
      "Remote execution:\n",
      "  --host file           Configuration file for remote computer. (default:\n",
      "                        None)\n",
      "  --to-host dir [dir ...]\n",
      "                        Files and directories to be sent to remote host for\n",
      "                        use in benchmark. (default: None)\n",
      "\n",
      "Other options:\n",
      "  --version             show program's version number and exit\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "dsc -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we elaborate on some of options we did not have space to elaborate on the interface:\n",
    "\n",
    "*  `-v` controls verbosity level. Default level is 2 (recommended), which displays necessary runtime info and uses a progressbar to display DSC progress. This verbosity level is typically good enough to hide trivial information yet report back errors. When these prompts are not sufficient to fix problems, it is very likely you run into a software bug. It would be very helpful if you could reproduce the bug with increased verbosity level (eg `-v4`) and post the problem to a [github issue](https://github.com/stephenslab/dsc/issues).\n",
    "\n",
    "* `--target`: this option takes multiple input. \n",
    "  * When used without `--clean` it overrides `DSC::run`, where DSC benchmark is defined. For example, benchmark in DSC file\n",
    "  \n",
    "      ```\n",
    "      run: simulate * method * score\n",
    "      ```\n",
    "      \n",
    "      can be re-defined with, for example `--target \"simulate * method\"` so that the pipeline `simulate * target` will be executed instead. Using this option, one can execute DSC bit by bit to debug, eg, `\"simulate\"`, then `\"simulate * method\"` and finally `\"simulate * method * score\"`.\n",
    "  * When used with `--clean` it specifies the module(s) whose output are to be \"clean\"-ed up (defined by behavior specified in `--clean`). Therefore only names of modules or ensembles are valid input in this context, not pipelines for benchmark.\n",
    "* `--skip`: unlike with `Make` / `Snakemake` that determines whether or not to re-execute based on time stamps, DSC creates HASH for modules that takes into consideration all input parameter, input and output module variables, and the content of the module script if applicable. When all these information agree with a previous execution it will by default skip those runs. This behavior can be changed by this `--skip` option. \n",
    "  * `--skip none` will re-execute everything: it will remove and ignore any existing output files. \n",
    "  * `--skip all` will not perform any module computations. It will only construct the execution meta-data and create a DSC database that one can query from. That is, `dsc <script> --skip all` followed by `dsc-query <output> -o` will help one understand the expected results from specified DSC benchmark. This can also be used as sanity check when benchmark is only partially completed. If you are uncertain about the scale of the benchmark, for example, it is recommanded to run DSC with `--skip all` and use `dsc-query <output> -o` to view the benchmark structure.\n",
    "* `-c` configures parallel computing. Since DSC is designed to be executed in either local or remote computers, `-c` configures the number of CPU threads used when computing in local and number of jobs to be sent when computing on the remote computers, when used with `--host` option (which will override `max_running_jobs` in the configuration file). Default value is in fact set to using half of the local computers CPU threads. Thus the displayed default `4` CPUs in the documentation above is result of running `dsc -h` on a computer with a total of 8 CPU threads. This number should be specifically configured if one wants to use more (or less) computing power on a desktop; and should definitely be configured for remote job executions based on current queue status of the remote computing environment.\n",
    "* `--ignore-errors` is a flag which, when added, will ignore errors from user provided scripts, thus keeps the benchmark running. There are often situations when we use other people's software packages that produces errors in random corner cases that will interrupt the benchmark from moving forward; sometimes one cannot `try ... catch` them. With this option, instead of throwing an error, DSC will **store the problematic chunk of code that resulted in an error to the output, creating a dummy output file that keeps DSC moving**. These dummy output will natually result in a chain reaction of failure in every other module that depends on them. But the benchmark will therefore complete, after which one can check the output and trace back the most upstream dummy output as source of errors.\n",
    "* `--distribute`: **FIXME: removed since version 0.2.2 because of pending design decision on how DSC is to be shared. Future version may bring back this feature if our DSC server is properly configured and regularly maintained.** This option will bundle the DSC benchmark into a tarball that can be uploaded to DSC shiny server for data query and visualization, or be transfered to other computational environments. DSC benchmarks should be released and shared with this command. When used without any argument it will pack DSC configuration, project meta data and available output into a tarball. To port the complete benchmark, one should specify additional files such as computational scripts and data used, eg, `--distribute /path/to/scripts /path/to/data`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC query program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a companion program to `dsc` that can be used to extract results from benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: dsc-query [-h] [--version] -o str [--limit N] [--title str]\n",
      "                 [--description str [str ...]] [-t WHAT [WHAT ...]]\n",
      "                 [-c WHERE [WHERE ...]] [-g G:A,B [G:A,B ...]]\n",
      "                 [--language str] [--addon str [str ...]]\n",
      "                 [--rds {omit,overwrite}] [-v {0,1,2,3}]\n",
      "                 DSC output folder or a single output file\n",
      "\n",
      "An internal command to extract meta-table for DSC results (requires 'sos-\n",
      "essentials' package to use notebook output).\n",
      "\n",
      "positional arguments:\n",
      "  DSC output folder or a single output file\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             show program's version number and exit\n",
      "  -o str                Output notebook / data file name. In query\n",
      "                        applications if file name ends with \".csv\", \".ipynb\"\n",
      "                        or \".xlsx\" then only data file will be saved as result\n",
      "                        of query. Otherwise both data file in \".xlsx\" format\n",
      "                        and a notebook that displays the data will be saved.\n",
      "                        (default: None)\n",
      "  --limit N             Number of rows to display for tables. Default is to\n",
      "                        display it for all rows (will result in very large\n",
      "                        HTML output for large benchmarks). (default: -1)\n",
      "  --title str           Title for notebook file. (default: DSC summary &\n",
      "                        query)\n",
      "  --description str [str ...]\n",
      "                        Text to add under notebook title. Each string is a\n",
      "                        standalone paragraph. (default: None)\n",
      "  -t WHAT [WHAT ...], --target WHAT [WHAT ...]\n",
      "                        Query targets. (default: None)\n",
      "  -c WHERE [WHERE ...], --condition WHERE [WHERE ...]\n",
      "                        Query conditions. (default: None)\n",
      "  -g G:A,B [G:A,B ...], --groups G:A,B [G:A,B ...]\n",
      "                        Definition of module groups. (default: None)\n",
      "  --language str        Language kernel to switch to for follow up analysis in\n",
      "                        notebook generated. (default: None)\n",
      "  --addon str [str ...]\n",
      "                        Scripts to load to the notebooks for follow up\n",
      "                        analysis. Only usable in conjunction with \"--\n",
      "                        language\". (default: None)\n",
      "  --rds {omit,overwrite}\n",
      "                        Convert Python serialized files to R serialized files\n",
      "                        (default: None)\n",
      "  -v {0,1,2,3}, --verbosity {0,1,2,3}\n",
      "                        Output error (0), warning (1), info (2) and debug (3)\n",
      "                        information. (default: 2)\n"
     ]
    }
   ],
   "source": [
    "dsc-query -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To query result\n",
    "\n",
    "The main goal of `dsc-query` is to extract results from benchmark given conditions. Although `dsc-query` works as is, we are extending it to meet language specific demands by creating separate software packages that wraps this command and enhances it -- the approach differs from language to language and will be documented in language specific manner. Therefore we will not provide in-depth documentation to this program.\n",
    "\n",
    "Currently supported languages specific libraries are:\n",
    "\n",
    "- R: `dsc_query` function for [`dscrutils` package](https://github.com/stephenslab/dsc/tree/master/dscrutils)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To dump single file from DSC benchmark to text\n",
    "\n",
    "`dsc-query` can also be used to browse single benchmark output file in `rds` or `pkl` format. For example:\n",
    "\n",
    "```\n",
    "dsc-query dsc_result/simulate/data_1.pkl -o data.out\n",
    "INFO: Loading database ...\n",
    "INFO: Data dumped to text files data.out and data.out.debug.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "celltoolbar": true,
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.9.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
