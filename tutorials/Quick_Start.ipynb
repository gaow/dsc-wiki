{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use DSC to compare methods implemented in [R](https://cran.r-project.org/) for location parameter estimations, based on this DSCR example ([R Markdown version](https://github.com/stephens999/dscr/blob/master/vignettes/one_sample_location.rmd) and [HTML version](dscr_one_sample_location.html)). Material used in this document can be found in [DSC2 vignettes repo](https://github.com/stephenslab/dsc2/tree/master/vignettes/one_sample_location).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC Specification\n",
    "The DSC problem is to assess location parameter estimation methods using simulation studies. We will simulate data under normal distribution and *t* distribution with 2 degrees of freedom; then estimate the location parameter using mean and median, and finally compare the performance of estimators using 2 loss functions: squared mean error and absolute mean error. The problem is fully specified in DSC2 language below:\n",
    "\n",
    "```\n",
    "normal: normal.R\n",
    "  n: 100\n",
    "  $data: x\n",
    "  $true_mean: 0\n",
    "\n",
    "t: t.R\n",
    "  n: 100\n",
    "  df: 2\n",
    "  $data: x\n",
    "  $true_mean: 3\n",
    "\n",
    "mean: mean.R\n",
    "  x: $data\n",
    "  $est_mean: y\n",
    "\n",
    "median: median.R\n",
    "  x: $data\n",
    "  $est_mean: y\n",
    "\n",
    "sq_err: sq.R\n",
    "  a: $est_mean\n",
    "  b: $true_mean\n",
    "  $error: e\n",
    " \n",
    "abs_err: abs.R\n",
    "  a: $est_mean\n",
    "  b: $true_mean\n",
    "  $error: e \n",
    "  \n",
    "DSC:\n",
    "    define:\n",
    "      simulate: normal, t\n",
    "      analyze: mean, median\n",
    "      score: abs_err, sq_err\n",
    "    run: simulate * analyze * score\n",
    "    exec_path: R\n",
    "    output: dsc_result\n",
    "```\n",
    "\n",
    "All computational routines in this DSC are R scripts, located in directories as specified in the `DSC::exec_path` property of the configuration file. Contents of these R scripts are:\n",
    "\n",
    "```r\n",
    "==> normal.R <==\n",
    "x = rnorm(n,0,1)\n",
    "\n",
    "==> t.R <==\n",
    "x = 3+rt(n,df)\n",
    "\n",
    "==> mean.R <==\n",
    "y = mean(x)\n",
    "\n",
    "==> median.R <==\n",
    "y = median(x)\n",
    "\n",
    "==> sq.R <==\n",
    "e = (a-b)^2\n",
    "\n",
    "==> abs.R <==\n",
    "e = abs(a-b)  \n",
    "```\n",
    "\n",
    "It is important to ensure the variable names match between R script and DSC files. For example the first syntax block involves computational routine `normal.R`, which takes parameter `n` and generate output `x`. The R script, `normal.R`, is `x = rnorm(n,0,1)`, which uses parameters `n` on the right hand side to produce `x` on the left hand side, consistent with output specified for module `normal`. The same holds for all other modules.\n",
    "\n",
    "The `DSC::run` property reflects a typical DSC setup where `normal` and `t` create *simulate* under various settings, `mean` and `median` are both methods to *analyze*, and `sq_err` and `abs_err` are *score*s that evaluate for performance. Therefore ensembles `simulate`, `analyze` and `score` are created using `DSC::define` and are used to build a benchmark with `*` logic to create various pipelines via combinations of modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gaow/GIT/dsc2/vignettes/one_sample_location"
     ]
    }
   ],
   "source": [
    "%cd ~/GIT/dsc2/vignettes/one_sample_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DSC\n",
    "To execute the DSC on a computer using 30 CPU threads,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mINFO: Checking R library dscrutils@stephenslab/dsc2/dscrutils ...\u001b[0m\n",
      "INFO: DSC script exported to \u001b[32mdsc_result.html\u001b[0m\n",
      "INFO: Constructing DSC from \u001b[32msettings.dsc\u001b[0m ...\n",
      "INFO: Building execution graph & running DSC ...\n",
      "DSC: 100%|██████████████████████████████████████| 15/15 [00:03<00:00,  3.94it/s]\n",
      "INFO: Building DSC database ...\n",
      "INFO: DSC complete!\n",
      "INFO: Elapsed time \u001b[32m6.928\u001b[0m seconds.\n"
     ]
    }
   ],
   "source": [
    "! dsc settings.dsc -c 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this example the results will be stored in folder `dsc_result/`. We will discuss these results later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run DSC\n",
    "DSC keeps track of completed tasks so that if the same module instance is re-executed it will skip the computation. For example if you rerun this command it will end quickly, because all computations are skipped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[{\"name\":\"stderr\",\"text\":\"INFO: DSC script exported to \\u001b[32msettings.html\\u001b[0m\\nINFO: Constructing DSC from \\u001b[32msettings.dsc\\u001b[0m ...\\n\\rDSC:   0%|          | 0/11 [00:00<?, ?it/s]\\rDSC:   9%|▉         | 1/11 [00:00<00:01,  9.44it/s]\\rDSC:  27%|██▋       | 3/11 [00:00<00:00, 10.96it/s]\\rDSC:  64%|██████▎   | 7/11 [00:00<00:00, 13.82it/s]\\rDSC: 100%|██████████| 11/11 [00:00<00:00, 17.11it/s]\\nINFO: Building output database \\u001b[32mdsc_result.rds\\u001b[0m ...\\nINFO: DSC complete!\\nINFO: Elapsed time \\u001b[32m1.865\\u001b[0m seconds.\\n\",\"output_type\":\"stream\"}]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DSC script exported to \u001b[32mdsc_result.html\u001b[0m\n",
      "INFO: Constructing DSC from \u001b[32msettings.dsc\u001b[0m ...\n",
      "INFO: Building execution graph & running DSC ...\n",
      "DSC: 100%|██████████████████████████████████████| 15/15 [00:02<00:00,  7.09it/s]\n",
      "INFO: Building DSC database ...\n",
      "INFO: DSC complete!\n",
      "INFO: Elapsed time \u001b[32m4.010\u001b[0m seconds.\n"
     ]
    }
   ],
   "source": [
    "! dsc settings.dsc -c 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the last line of output records elapsed time of ~4.4 seconds, compared to ~11 seconds in the first run. If you want to ignore existing result you can use the `--skip none` flag to force DSC rerun existing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[{\"name\":\"stderr\",\"text\":\"INFO: DSC script exported to \\u001b[32msettings.html\\u001b[0m\\nINFO: Constructing DSC from \\u001b[32msettings.dsc\\u001b[0m ...\\n\\rDSC:   0%|          | 0/11 [00:00<?, ?it/s]\\rDSC:   9%|▉         | 1/11 [00:01<00:18,  1.83s/it]\\rDSC:  27%|██▋       | 3/11 [00:05<00:14,  1.78s/it]\\rDSC:  45%|████▌     | 5/11 [00:05<00:07,  1.26s/it]\\rDSC:  64%|██████▎   | 7/11 [00:08<00:05,  1.37s/it]\\rDSC:  73%|███████▎  | 8/11 [00:08<00:02,  1.01it/s]\\rDSC:  82%|████████▏ | 9/11 [00:08<00:01,  1.39it/s]\\rDSC: 100%|██████████| 11/11 [00:08<00:00,  1.92it/s]\\nINFO: Building output database \\u001b[32mdsc_result.rds\\u001b[0m ...\\nINFO: DSC complete!\\nINFO: Elapsed time \\u001b[32m10.278\\u001b[0m seconds.\\n\",\"output_type\":\"stream\"}]",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DSC script exported to \u001b[32mdsc_result.html\u001b[0m\n",
      "INFO: Constructing DSC from \u001b[32msettings.dsc\u001b[0m ...\n",
      "INFO: Building execution graph & running DSC ...\n",
      "DSC: 100%|██████████████████████████████████████| 15/15 [00:03<00:00,  4.40it/s]\n",
      "INFO: Building DSC database ...\n",
      "INFO: DSC complete!\n",
      "INFO: Elapsed time \u001b[32m5.787\u001b[0m seconds.\n"
     ]
    }
   ],
   "source": [
    "! dsc settings.dsc -c 30 --skip none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DSC script browser\n",
    "DSC commands generates a script browser in HTML format. In this example it is [`dsc_result.html`](dsc_result.html) under your work directory. You can use a web browser to open it. This file contains the DSC configuration, executed pipelines as well as source code for each pipeline in the benchmark.\n",
    "\n",
    "## DSC results\n",
    "Results of this DSC is stored in the folder `dsc_result/`. It has numerous files for each module instance involved in the DSC benchmark. Please continue on the [next tutorial](Explore_Output.html) to extract and analyze the benchmark results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "celltoolbar": true,
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
