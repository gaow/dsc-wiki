{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC Basics, Part II\n",
    "\n",
    "This is the second part of the \"DSC Basics\" tutorial. Before working through this tutorial, you should have already read [DSC Basics, Part I](Intro_Syntax_I.html). Here we build on the mean estimation example from the previous part to illustrate new concepts and syntax in DSC, with an emphasis on the use of *module parameters*.\n",
    "\n",
    "Materials used in this tutorial can be found in the [DSC vignettes repository](https://github.com/stephenslab/dsc/tree/master/vignettes/one_sample_location). As before, you may choose to run this example DSC program as you read through the tutorial, but this is not required. For more details, consult the README in the [\"one sample location\" DSC vignette](https://github.com/stephenslab/dsc/tree/master/vignettes/one_sample_location)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a module parameter to `normal`\n",
    "\n",
    "In our example DSC, recall we defined the `normal` module as follows:\n",
    "\n",
    "```\n",
    "normal: R(x <- rnorm(n = 100,mean = 0,sd = 1))\n",
    "  $data: x\n",
    "  $true_mean: 0\n",
    "```\n",
    "\n",
    "Here we propose to make a slight improvement to this module by adding a *module parameter*, `n`:\n",
    "\n",
    "```\n",
    "normal: R(x <- rnorm(n,mean = 0,sd = 1))\n",
    "  n: 100\n",
    "  $data: x\n",
    "  $true_mean: 0\n",
    "```\n",
    "\n",
    "We have defined a module parameter `n` and set its value to 100. Once we have defined `n`, any of the R code may refer to this module parameter. In the R code, the first argument of `rnorm` is set to the value of `n` (which is 100).\n",
    "\n",
    "In this first example, there is not much benefit to defining a module parameter `n`. In the examples below, the advantages of module parameters will become more apparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a second module parameter to `normal`\n",
    "\n",
    "In our current design of `normal`, we made an unfortunate choice: the mean used to simulate the data is defined twice, once inside the call to `rnorm`, where we set `mean = 0`, and once when we set the module output `$true_mean` to zero. If we decide to use a different mean to simulate the data, then we would have to be careful to change the code in two different places. \n",
    "\n",
    "It would be better if the mean of the data was defined once. This can be accomplished with a module parameter, which we will name `mu` (the Greek letter conventionally used to denote the mean):\n",
    "\n",
    "```\n",
    "normal: R(x <- rnorm(n,mean = mu,sd = 1))\n",
    "  n: 100\n",
    "  mu: 0\n",
    "  $data: x\n",
    "  $true_mean: mu\n",
    "```\n",
    "\n",
    "Here, we have defined a second module parameter `mu`, and set its value zero. Now the `mean` argument of `rnorm` can be set to the value of `mu`. \n",
    "\n",
    "Additionally, since `mu` is also a script parameter, the module output `$true_mean` can be set to the value of (script parameter) `mu`. (In this example, the value of the module parameter happens to be the same as the value of the variable `mu` used in the R code, but in some cases the R code might modify the value of `mu`, in which case the module parameter and script parameter will be different. So it is important to keep these quantities distinct.)\n",
    "\n",
    "With this change to the module definition, modifying the mean used to simulate the data only requires editing one line of code instead of two.\n",
    "\n",
    "Likewise, we can use a module parameter to specify the mean of the data simulated from a *t* distribution:\n",
    "\n",
    "```\n",
    "t: R(x <- mu + rt(n,df = 2))\n",
    "  n: 100\n",
    "  mu: 3\n",
    "  $data: x\n",
    "  $true_mean: mu\n",
    "```\n",
    "\n",
    "Note that there is no requirement that the module parameters for the `normal` and `t` modules have the same name, `mu`, but in this case makes sense to do so. One advantage of defining parameters with the same name is that makes it easier to query the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The order of evaluation inside a module\n",
    "\n",
    "In the examples above, we informally introduced the notion of a *model parameter.* Below, we will give some more elaborate examples with module parameters, so here we take a moment to describe more formally how a module parameter behaves in relation to other components of a module:\n",
    "\n",
    "+ A module parameter cannot depend on any of the module inputs, and it can only depend on other module parameters through use of the `raw` keyword (this is explained below). In other words, it must be possible to evaluate the module parameter without knowing the values of the module inputs or the values of the other module parameters (again, the one exception is when `raw` is used).\n",
    "\n",
    "+ Module parameters are evaluated before the module script (except when `raw` is used—see below). The exact procedure for evaluating a module is as follows:\n",
    " \n",
    "    1. Evaluate any R code used to determine the values of the module parameters (we give an example of this below).\n",
    "    \n",
    "    2. Set the values of the module parameters (except for module parameters defined with `raw`).\n",
    "    \n",
    "    3. Initialize the module inputs according to the current stored values of the pipeline variables.\n",
    "    \n",
    "    4. For each module parameter and module input, define a *script variable* in the global environment in which the script is evaluated with the same name and same value as the module parameter or input. \n",
    "    \n",
    "    5. Evaluate the module script or inline source code. All script variables are retained for resolving any module outputs.\n",
    "    \n",
    "    6. Set each module output to the stored value of the selected script variable.\n",
    "\n",
    "If this evaluation procedure is unclear to you at this stage, it will will become more clear as we work through the examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A single module parameter with multiple alternative values\n",
    "\n",
    "Above, we gave a couple examples of defining module parameters. Here, we will demonstrate an important feature of module parameters: they can be used to define multiple modules that are similar to each other.\n",
    "\n",
    "Our current definition of the `normal` module simulates 100 random samples from a normal distribution. Suppose we would like to define a second module that simulates 1,000 random samples from the same normal distribution. This is easily done by defining a new module parameter `n` that takes on two different values:\n",
    "\n",
    "```\n",
    "normal: R(x <- rnorm(n,mean = mu,sd = 1))\n",
    "  mu: 0\n",
    "  n: 100, 1000\n",
    "  $data: x\n",
    "  $true_mean: mu\n",
    "```\n",
    "\n",
    "The comma delimits the two possible values of model parameter `n`.\n",
    "\n",
    "Now that we have defined `n` inside this module, we can refer to this module parameter inside the R code that simulates random draws from a normal distribution, as in the example above.\n",
    "\n",
    "To be precise, this code defines a *module block* with two modules. It is equivalent to defining two modules, `normal_100` and `normal_1000`, that are identical in every way except that the first module includes parameter definition `n: 100` and the second defines `n: 100`. The module block above is of course much more succinct.\n",
    "\n",
    "The line `n: 100, 1000` should not be interpreted as defining a vector or sequence with two entries, 100 and 1000. It defines a *set of alternative values*. To put it another way—and this is the terminology we use frequently—`n: 100, 1000` defines two *alternative values* for module parameter `n`, and therefore defines two *alternative modules* that are the same in every way (including their name, `normal`) except for the setting of `n`.\n",
    "\n",
    "An important property of module parameters with multiple alternative values is that *their order does not matter*. For example, if we instead wrote `n: 1000, 100`, *the DSC results will be exactly the same as* `n: 100, 1000`. The only thing that will change is the order in which the results will appear in the tables, and the way in which the results are stored in files.\n",
    "\n",
    "Although the two modules both have the same name, `normal`, their outputs can still be easily distinguished in the results; for example, if you want to compare the accuracy of the estimates in the larger (`n = 1000`) and smaller (`n = 100`) simulated data sets, the results from these two modules can be distinguished by the stored value of the module parameter `n`. We will see an example of this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the DSC with alternative `simulate` modules\n",
    "\n",
    "Let's go ahead and generate results from our new \"mean estimation\" DSC. In the new DSC, the `simulate` modules are defined by two module blocks:\n",
    "\n",
    "```\n",
    "normal: R(x <- rnorm(n,mean = mu,sd = 1))\n",
    "  mu: 0\n",
    "  n: 100, 1000\n",
    "  $data: x\n",
    "  $true_mean: mu\n",
    "\n",
    "t: R(x <- mu + rt(n,df = 2))\n",
    "  mu: 3\n",
    "  n: 100, 1000\n",
    "  $data: x\n",
    "  $true_mean: mu\n",
    "```\n",
    "\n",
    "The rest of the DSC remains unchanged from before.\n",
    "\n",
    "This new DSC is implemeted by `simulate_data_twice.dsc` inside the `one_sample_location` vignette folder. \n",
    "\n",
    "To run the DSC benchmark, change the working directory (here we have assumed that the dsc repository is stored in the `git` subdirectory of your home directory),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pcarbo/git/dsc/vignettes/one_sample_location\n"
     ]
    }
   ],
   "source": [
    "cd ~/git/dsc/vignettes/one_sample_location\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove any previously generated results,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "rm -Rf first_investigation.html first_investigation.log first_investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then let's run 10 replicates of all the pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DSC script exported to \u001b[32mfirst_investigation.html\u001b[0m\n",
      "INFO: Constructing DSC from \u001b[32msimulate_data_twice.dsc\u001b[0m ...\n",
      "INFO: Building execution graph & running DSC ...\n",
      "DSC: 100%|██████████████████████████████████████| 15/15 [00:47<00:00,  2.37s/it]\n",
      "INFO: Building DSC database ...\n",
      "INFO: DSC complete!\n",
      "INFO: Elapsed time \u001b[32m49.815\u001b[0m seconds.\n"
     ]
    }
   ],
   "source": [
    "dsc simulate_data_twice.dsc --replicate 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TO DO: Add a sentence here pointing out the number of module outputs that were generated by this command.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the DSC results with `n=100` and `n=1000`\n",
    "\n",
    "Now we will view the DSC results in R. Change the R working directory to the location of the DSC file, and use the dscquery function from the `dscrutils` package to load the DSC results into R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running shell command:\n",
      "dsc-query first_investigation -o /var/folders/9b/ck4lp8s140lcksryyh4dppdr0000gn/T//RtmpU40I0r/file5f34164f5246.csv -f --target simulate.n simulate.true_mean analyze score.error \n",
      "Loading dsc-query output from CSV file.\n",
      "Reading DSC outputs:\n",
      " - simulate.true_mean: extracted atomic values\n",
      " - score.error: extracted atomic values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "160"
      ],
      "text/latex": [
       "160"
      ],
      "text/markdown": [
       "160"
      ],
      "text/plain": [
       "[1] 160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setwd(\"~/git/dsc/vignettes/one_sample_location\")\n",
    "library(dscrutils)\n",
    "dscout <-\n",
    "  dscquery(dsc.outdir = \"first_investigation\",\n",
    "           targets = c(\"simulate.n\",\"analyze\",\"score.error\"))\n",
    "nrow(dscout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DSC command we ran above generated results for 10 replicates of 16 pipelines, doubling the number of pipelines we had before. This is expected because we now have 4 `simulate` modules (2 `normal` modules and 2 `t` modules), whereas before we had 2 `simulate` modules. To confirm this, we see that each of the `simulate` modules is run 40 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        simulate.n\n",
       "simulate 100 1000\n",
       "  normal  40   40\n",
       "  t       40   40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(dscout,table(simulate,simulate.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect that estimates improve with more data. We can quickly check this by comparing the average error (e.g., the squared error) in the pipelines with 100 samples against the average error in the pipelines with 1000 samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            100     1000\n",
       "mean   0.308991 0.004709\n",
       "median 0.015792 0.002163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat <- subset(dscout,score == \"sq_err\")\n",
    "as.table(by(dat,\n",
    "            with(dat,list(analyze,simulate.n)),\n",
    "            function (x) mean(x$score.error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, based on the results from these 10 replicates, we see that the accuracy of both methods (mean and median) improves considerably with more data, on average, and in both cases the median is more accurate than the mean on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two module parameters with multiple alternatives\n",
    "\n",
    "If you provide more than one value for multiple module parameters, DSC considers all combinations of the values. \n",
    "\n",
    "For example, suppose we want to evaluate estimators of the population mean when the data are simulated from the *t* distribution with different numbers of degrees of freedom. In DSC, this can be compactly expressed by defining another module parameter, `df`, with multiple values:\n",
    "\n",
    "```\n",
    "t: R(x <- mu + rt(n,df))\n",
    "  mu: 3\n",
    "  df: 2, 4, 10\n",
    "  n: 100, 1000\n",
    "  $data: x\n",
    "  $true_mean: mu\n",
    "```\n",
    "\n",
    "This defines 6 `t` modules from the 6 different ways of setting both the `n` and `df` parameters.\n",
    "\n",
    "Next, let's clear the previous results and run the new DSC benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DSC script exported to \u001b[32mfirst_investigation.html\u001b[0m\n",
      "INFO: Constructing DSC from \u001b[32msimulate_multiple_dfs.dsc\u001b[0m ...\n",
      "INFO: Building execution graph & running DSC ...\n",
      "DSC: 100%|██████████████████████████████████████| 15/15 [01:55<00:00,  6.08s/it]\n",
      "INFO: Building DSC database ...\n",
      "INFO: DSC complete!\n",
      "INFO: Elapsed time \u001b[32m118.543\u001b[0m seconds.\n"
     ]
    }
   ],
   "source": [
    "rm -Rf first_investigation.html first_investigation.log first_investigation\n",
    "dsc simulate_multiple_dfs.dsc --replicate 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TO DO: Add a sentence here pointing out the number of module outputs that were generated by this command.*\n",
    "\n",
    "Now let's load all the results generated with the *t*-simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running shell command:\n",
      "dsc-query first_investigation -o /var/folders/9b/ck4lp8s140lcksryyh4dppdr0000gn/T//RtmpU40I0r/file5f343992f15b.csv -f --target t.n t.df analyze score.error \n",
      "Loading dsc-query output from CSV file.\n",
      "Reading DSC outputs:\n",
      " - score.error: extracted atomic values\n"
     ]
    }
   ],
   "source": [
    "dscout2 <-\n",
    "  dscquery(dsc.outdir = \"first_investigation\",\n",
    "           targets = c(\"t.n\",\"t.df\",\"analyze\",\"score.error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, we have results from 240 pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      t.df\n",
       "t.n     2  4 10\n",
       "  100  40 40 40\n",
       "  1000 40 40 40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(dscout2,table(t.n,t.df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the 6 `t` modules was run 40 times: 2 analyze modules x 2 score modules x 10 replicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a module parameter to set the seed\n",
    "\n",
    "To ensure reproduceable results, it is often necessary to initialize the state, or \"seed\", for generating the sequence of pseudorandom numbers. DSC automatically provides a default setting for the seed in R, but you may want to override this choice. A common use of module parameters is to modules with different seeds.\n",
    "\n",
    "In this example, we define 10 modules that generate normally distributed data sets with 100 samples: \n",
    "\n",
    "```\n",
    "normal: R(set.seed(seed); x <- rnorm(n,mean = mu,sd = 1))\n",
    "  seed: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "  mu: 0\n",
    "  n: 100\n",
    "  $data: x\n",
    "  $true_mean: mu\n",
    "```\n",
    "\n",
    "The only difference in the 10 `normal` modules is the sequence of pseudorandom numbers used to simulate random draws from the normal distribution.\n",
    "\n",
    "See `multiple_seeds.dsc` in the `one_sample_location` directory for a working example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining module parameters with module inputs\n",
    "\n",
    "It is also possible to combine module parameters with module inputs.\n",
    "\n",
    "Recall, in the [introductory tutorial](Intro_DSC.html) we defined a third `analyze` module that implemented the \"Winsorized\" mean. The `trim` argument to `winsor.mean` determines the proportion of the data to \"squish\" from the top and bottom of the distributions. If we wanted to evaluate the impact that the trimming amount has on the accuracy of the estimate, we could introduce a module parameter `trim` with multiple settings:\n",
    "\n",
    "```\n",
    "winsor: R(y <- psych::winsor.mean(x,trim,na.rm = TRUE))\n",
    "  trim: 0.1, 0.2\n",
    "  x: $data\n",
    "  $est_mean: y\n",
    "```\n",
    "\n",
    "For each data set generated by a `simulate` module, DSC will run two different `winsor` modules: one with `trim = 0.1`, and a second with `trim = 0.2`.\n",
    "\n",
    "Intuitively, one may want to adjust the trim setting *dynamically* based on the data (e.g., based on the fit to the normal distribution). However, this is not possible in DSC because module parameters must be set independently of the module inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining more complex module parameters (incomplete)\n",
    "\n",
    "Above, we showed that DSC defines a module for each combination of the module parameters. Sometimes it is desirable to have finer control over which combinations are module parameters are used. One way to do this is to define a single module parameter that sets the value of multiple parameters used in the script. For example, suppose we wanted to simulate data from *t* distributions with these three settings of the mean (`mu`) and number of degrees of freedom (`df`):\n",
    "\n",
    "```\n",
    "mu  df\n",
    "--  --\n",
    " 0   2\n",
    " 1   2\n",
    " 2   4\n",
    "```\n",
    "\n",
    "This cannot be achieved by setting the module parameters `mu` and `df` separately because it will automatically define modules for all combinations of `mu` and `df`. Instead, we can do something like this:\n",
    "\n",
    "```\n",
    "t: R(mu <- par[1]; df <- par[2]; x <- mu + rt(n,df))\n",
    "  par: R(c(mu = 0,df = 2)),\n",
    "       R(c(mu = 1,df = 2)),\n",
    "       R(c(mu = 2,df = 4))\n",
    "  n: 100\n",
    "  $data: x\n",
    "  $true_mean: 3\n",
    "```\n",
    "\n",
    "In this example, `par` is a module parameter with 3 alternative settings, in which each alternative setting is a vector with two elements; the first vector element is the mean of the simulated data, and the second vector element is the number of degrees of freedom.\n",
    "\n",
    "Note that the text inside the `R()` is evaluated as R code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining module parameters with many alternative values (incomplete)\n",
    "\n",
    "Example for this section: \n",
    "\n",
    "Start with an example in which the different values of n are 10^1, 10^1.5, 10^2, etc, all defined within R().\n",
    "\n",
    "Then generate many simulated data sets with different values of n, from very small (10) to very large (1e6) using R{}. \n",
    "\n",
    "Finally, run the code and show that it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Add recap here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring further\n",
    "\n",
    "In this tutorial, we introduced the most essential features of DSC that are sufficient to . There are many other features of DSC that we did not have a chance to mention in these introductory tutorial.  "
   ]
  }
 ],
 "metadata": {
  "Rmd_header": {
   "author": "Matthew Stephens",
   "date": "2/26/2018",
   "output": "html_document",
   "title": "dsc_intro_partIII.rmd"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.9.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
