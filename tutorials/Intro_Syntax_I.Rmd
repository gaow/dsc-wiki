---
title: "Introduction to DSC (Part II)"
author: "Matthew Stephens, Gao Wang and Peter Carbonetto"
date: "March 21, 2018"
output: html_document
---

# Introduction to DSC (Part II)

This is a continuation of the
[Introduction to DSC (Part I)](First_Course.html). Here we revisit the
same example from the first part to illustrate key concepts of DSC,
including *modules*, *groups* and *pipeline variables*. More advanced
concepts will be introduced in [Part III]().

Materials used in this tutorial can be found in the
[DSC vignettes repository](https://github.com/stephenslab/dsc/tree/master/vignettes/one_sample_location). As
before, you may choose to run this example DSC program as you read
through the tutorial.

## Pipeline variables

In DSC, all information is passed from one module to another through
*pipeline variables*. All pipeline variables are indicated with a `$`
as the first character, as in `$data` or `$mean_test_error`.

Under the hood, when a module outputs a pipeline variable, the value
of this variable is saved to a file; and when a pipeline variable is
provided as input to a module, the value of this variable is read from
a file. You will never need to access these files directly; DSC
provides a user interface that allows you to access (*i.e.*, query)
the pipeline variables without having to know where or how they are
stored. In the previous tutorial we illustrated how the pipeline
variables can be queried in R.

## Planning a DSC file

The main aim of DSC is to make your benchmark, or computational
experiment, easier to read, easier to maintain, and easier to
extend. To achieve these aims, we recommend that you to start by
planning out your DSC project.

We suggest starting the planning by identifying the *module types*
(the key computational steps in your benchmark) and the *pipeline
variables* (the quantities being fed from one step to another). All
pipeline variables should be given informative names (which must begin
with a `$`). It is also helpful to give the modules informative names.
(*Note:* unlike other programming languages such as R, names in DSC
cannot have a period.)

In our working example, recall that we compared methods for estimating
a population mean from a simulated data sample. This example follows
the **simulate-analyze-score** design pattern, meaning that the
benchmark can be naturally decomposed into three module types:

+ A `simulate` module that generates a vector of simulated data
(`$data`), and the population mean setting used to simulate these data
(`$true_mean`).

+ An `analyze` module that accepts `$data` as input, and outputs an
estimate of the population mean (`$est_mean`).

+ A `score` module that accepts inputs `$est_mean` and `$true_mean`,
and outputs an error measure (`$error`).

Therefore, our DSC has four pipeline variables:
`$data`,`$true_mean`,`$est_mean` and `$error`.

We have summarized this information in the comments at the top of the
DSC file (the `#` character indicates a comment in a DSC
file—anything after a `#` is ignored by DSC):

```
# PIPELINE VARIABLES
# $data       simulated data (vector)
# $true_mean  population mean used to simulate $data (scalar)
# $est_mean   population mean estimate (scalar)
# $error      error in the estimate (scalar)
# 
# MODULE TYPES
# name     inputs                outputs
# ----     ------                -------
# simulate none                  $data, $true_mean
# analyze  $data                 $est_mean
# score:   $est_mean, $true_mean $error
```

## Two important notes about pipeline variables

1. The pipeline variables outputted by a module should be exactly the
parts of the module output that you want stored for future use. For
example, `$error` is here considered a pipeline variable since we
would like to use this quantity to study the results of the
experiment.

2. *The pipeline variables are the only way that modules can
communicate with one another.* So if a module requires access to a
piece of information generated by a previous module, then this must be
a pipeline variable. For example, a `score` module naturally requires
access to the true mean used to generate the data, so here this is
outputted as a pipeline variable from a `simulate` module. In other
words, *all information in a DSC program is local o each module unless
it is defined as a pipeline variable with the `$` character.*

## Defining modules in a DSC file

At its simplest, a DSC module definition consists of a name, a script
(code) implementing the module, and details of how pipeline variables
are to be passed in and out of the script.

Here we illustrate the syntax by explaining each module in our
example. To keep the presentation focused on the key concepts, we use
a slightly simplified version of the
[mean estimation example](Intro_DSC.html) that achieves the same
result; see file `first_investigation_simpler.dsc` in the
[DSC vignettes repository](https://github.com/stephenslab/dsc/tree/master/vignettes/one_sample_location)
for the full example.

### The `normal` module

The first module defined in the DSC file is the `normal` module:

```
normal: R(x <- rnorm(n = 100,mean = 0,sd = 1))
  $data: x
  $true_mean: 0
```

(Again, this code is simplified slightly from the previous tutorial,
but it achieves the same result.)

This code tells DSC three things:

1. The name of the module is "normal".

2. The R script implementing the module is a single line of code: `x
   <- rnorm(n,mean = mu,sd = 1)`. Here, `R()` tells DSC that this code
   should be parsed and evaluated as an R script. For longer code,
   this should be replaced with a name of a file containing the R
   code. Any global variables defined inside a script are called
   "script variables"; in this module, one script variable is defined,
   `x`.

3. After running the script, the pipeline variable `$data` is
   determined by the value of script variable `x`. A second
   pipeline variable, `$true_mean`, is set to 0.

### The `t` module

The `t` module has the same outputs as the `normal` module, but
generates `$data` from a *t* distribution with a mean of 3 and 2
degrees of freedom. After running the script, the pipeline variable
$data is assigned the value of script variable `x`, and
`$true_mean` is set to 0.

Here is the code:

```
t: R(x <- 3 + rt(n = 100,df = 2))
  $data: x
  $true_mean: 3
```

### The two `analyze` modules

Our example has two `analyze` modules: the `mean` module estimates the
population mean by the sample mean, and the `median` module estimates
the population mean by the sample median.

They are defined in the DSC file as follows:

```
mean: R(y <- mean(x))
  x: $data
  $est_mean: y
  
median: R(y <- median(x))
  x: $data
  $est_mean: y
```

These modules differ from the `simulate` modules in that they have
inputs in addition to outputs:

+ The line `x: $data` specifies a module input. It tells DSC that, at
  the beginning of the R code, it should define a new script variable
  `x`, and set the value of `x` to the value of the pipeline variable
  `$data`. The value of `$data` is given by the most recently run
  module in the pipeline that assigned a value to `$data`.

+ The line `$est_mean: y` specifies a module output. It tells DSC
  that after running the script it should set the value of the
  pipeline variable `$est_mean` to the value of the script variable
  `y`.

**Important note:** Although the R code in the `normal`,`t`,`median`
and `mean` modules all define a script variable `x`, these variables
are distinct, and we must use a pipeline variable (here `$data`) to
pass the information on `x` from one script to another.

In summary, all script variables are local to each module, and
information can flow from one module to another only through pipeline
variables.

### The two `score` modules

Finally, we create two `score` modules that measure error in the
estimate, one based on squared differences (`sq_err`) and another
based on absolute differences (`abs_err`):

```
sq_err: R(e <- (x - y)^2)
  x: $est_mean
  y: $true_mean
  $error: e
 
abs_err: R(e <- abs(x - y))
  x: $est_mean
  y: $true_mean
  $error: e 
```

The inputs to both modules are `$est_mean` and `$true_mean`, and the
output is `$error`.

In each of these modules, there are three script variables:

1. `x`, set to the current value of pipeline variable `$est_mean`.

2. `y`, set to the current value of pipeline variable `$true_mean`.

3. `e`, which is determined by the R code, and its value is assigned
   to pipeline variable $error$.

This completes the module definitions.

## Defining groups and pipelines

So far, we have defined the modules—that is, the individual
computational steps of the DSC experiment—but we have not yet
described how these modules relate to each other, and how they are
used to build pipelines. This is the purpose of the `DSC` block in the
DSC file; the key components of the `DSC` block are the `define` and
`run` statements.

```
DSC:
  define:
    simulate: normal, t
    analyze: mean, median
    score: abs_err, sq_err
  run: simulate * analyze * score
```

This code does the following:

1. `DSC` is a special keyword indicating that we are defining the
   module groups and pipelines (that is, we are not defining a module).

2. `define` is another keyword indicatingthat we are defining module
   groups.

3. We define three module groups: `simulate`, `analyze` and `score`.
   The defining characteristic of module groups is that they should
   have a similar function (and, ideally, the same inputs and outputs,
   although this is not required).

4. `run` is a keyword indicating that we are defining the
   computational pipelines (sequences of modules) to be executed.

+ The `A * B` notation asks DSC to generate all possible sequences of
  modules from groups `A` and `B`; that is, all sequences of the form
  (`a`, `b`) where `a` is a module in group `A` and `b` is a module in
  a group `B`. So, in this example, `simulate * analyze * score`
  generates all pipelines that consist of a module from the `simulate`
  group (`normal` or `t`), followed by a module from the `analyze`
  group (`mean` or `median`), and then a module from the `score` group
  (`sq_err` or `abs_err`). In this example, there are $2 \times 2
  \times 2 = 8$ different pipelines defined by this `run` statement.

## Executing the DSC benchmark and inspecting the results

Up to this point, all we have is a bunch of code stored in a text
file; the DSC file doesn't do anything unless it is interpreted and
executed by the `dsc` program.

The `dsc` program will run all the pipelines, keeping track of the
values of all the script variables and pipeline variables generated in
each pipeline, and storing the values of the module outputs for our
subsequent analysis in R.

To run the DSC benchmark, change the working directory to the
location of the `first_investigation_simpler.dsc` file.

```
cd ~/git/dsc/vignettes/one_sample_location
pwd
```

Let's also remove any previously generated results.

```
rm -Rf first_investigation.html first_investigation.log first_investigation
```

To keep this example as simple as possible, let's generate only a
single replicate for each of the pipelines, and we will run the
pipelines in parallel on 2 CPUs, if available:

```
dsc first_investigation_simpler.dsc --replicate 1 -c 2
```

*TO DO: Add a sentence here pointing out the number of module outputs
 that were generated by this command.*

To inspect the pipelines that were run, and the module outputs that
were generated in each of these pipelines, we change the R working
directory to the location of the DSC file, and use the `dscquery`
function from the `dscrutils` package to load the DSC results into R:

```
setwd("~/git/dsc/vignettes/one_sample_location")
library(dscrutils)
dscout <-
  dscquery(dsc.outdir = "first_investigation",
           targets = c("simulate.true_mean","analyze.est_mean","score.error"))
dscout
```

A few remarks at this point:

1. Looking at the "simulate", "analyze" and "score" table columns,
we see that DSC has run 8 different pipelines, corresponding to each
possible combination of the `simulate`, `analyze` and `score` modules.

2. Each module output is assigned a value in each of the 8 pipelines,
and these values are now accessible in the data frame. (We did not
include vector `simulate.data` because it is too large to show in this
table, but its can value can be queried like this other outputs.)

3. The information flow happens across the modules *within the same
pipeline*. For example, in the first pipeline (the first row of the
table), the error in the `abs_err` module (0.05858) is calculated from
the value of the true mean, which was set to 0 in the `normal` module,
and from the estimated mean, which was set to 0.05858 in the `mean`
module.

## Recap

In this tutorial, we learned how the DSC file is used to define the
key components of a DSC experiment:

1. Module inputs and outputs (pipeline variables);

2. Module scripts and script variables.

3. Module groups; and

3. Module sequences (pipelines).

## Next steps

In the [third introductory tutorial](Intro_Syntax_II.html), we will
extend this example and introduce a few other useful DSC features.

<!-- You can think of a pipeline variable as a variable whose value
may change as a pipeline is run. For example, in a pipeline `a-b-c`,
with modules `a`, `b` and `c`, if module `a` outputs a pipeline
variable `$data`, and then module `b` outputs `$data` with a new
value, then if module `c` inputs `$data` its value will be the one
output by `b` and not the one output by `a`. -->
