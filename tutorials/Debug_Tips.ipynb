{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging in DSC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module executable and generated script\n",
    "\n",
    "As seen from previous tutorials, the [module executables in DSC](dsc_result.html) are in fact incomplete because the lack input data and parameter specifications to run. Under the hood, DSC2 generates R, Python or Shell scripts based on module executable scripts, adding to it specification of module parameters and pipeline variables, then executes the complete script. This generated script is subject to two types of errors:\n",
    "\n",
    "1. Inconsistency between DSC interface and module executables\n",
    "2. Error from module executables as provided\n",
    " \n",
    "In the presence of errors DSC will fail. However the automatically generated script will be saved to disk and will be pointed to you as part of the error prompt on the command console so that you can reproduce and fix the bugs. \n",
    "\n",
    "Here we look at example from [location parameter estimations example](https://github.com/stephenslab/dsc2/tree/master/vignettes/one_sample_location). We undermine the setup to demonstrate the 2 types of errors we have discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buggy DSC interface\n",
    "\n",
    "To demonstrate inconsistency between interface and module we change the first block of DSC script from:\n",
    "\n",
    "```\n",
    "normal, t: rnorm.R, rt.R\n",
    "    seed: R(1:5)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```\n",
    "normal, t: rnorm.R, rt.R\n",
    "    weed: R(1:5)\n",
    "```\n",
    "\n",
    "creating a parameter `weed`, a typo of `seed`, that does not exist in `rnorm.R` and `rt.R`. Consequently the required `seed` variable for these routines will not be provided by DSC interface. We save this configuration file as `settings_error_v1.dsc` and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gaow/GIT/dsc2/vignettes/one_sample_location"
     ]
    }
   ],
   "source": [
    "%cd ~/GIT/dsc2/vignettes/one_sample_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[{\"output_type\":\"stream\",\"text\":\"INFO: DSC script exported to \\u001b[32mblm.html\\u001b[0m\\nINFO: Constructing DSC from \\u001b[32mblm.dsc\\u001b[0m ...\\nINFO: Building execution graph ...\\n\\rDSC:   0%|          | 0/10 [00:00<?, ?it/s]\\rDSC:  10%|█         | 1/10 [00:00<00:00,  9.67it/s]\\rDSC:  20%|██        | 2/10 [00:00<00:00,  9.12it/s]\\rDSC:  60%|██████    | 6/10 [00:00<00:00, 11.49it/s]\\rDSC:  90%|█████████ | 9/10 [00:00<00:00, 10.97it/s]\\n\\u001b[91mERROR\\u001b[0m: \\u001b[91mFailed to execute workflow DSC\\n[score_1 ['dsc_blm/datamaker.R_1_gemma_bs] RuntimeError:\\n\\tFailed to process statement sos_run('core_score_1:1', outp...ignature)\\\\n: Failed to execute workflow core_score_1\\n[core_score_1_1 (score.R)] RuntimeError:\\n\\tFailed to execute script (ret=1).\\nPlease use command\\n\\t\\u001b[32mRscript \\\\\\n\\t  --default-packages=datasets,methods,utils,stats,grDevices,graphics \\\\\\n\\t  /home/gaow/GIT/lab-dsc/dsc2-blm/.sos/core_score_1_1_6.R\\u001b[91m\\nunder \\\"/home/gaow/GIT/lab-dsc/dsc2-blm\\\" to test it.\\n[core_score_1] RuntimeError:\\n\\t1 failed step: core_score_1_1 (score.R)\\n[DSC] RuntimeError:\\n\\t1 failed step: score_1\\u001b[0m\\n\\u001b[95mWARNING\\u001b[0m: \\u001b[95mIf needed, you can open \\u001b[32mdsc_blm.transcript.html\\u001b[95m and use \\u001b[32mctrl-F\\u001b[95m to search for the problematic chunk of code by output file name.\\u001b[0m\\n\",\"name\":\"stderr\"}]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mINFO: Checking R library dscrutils@stephenslab/dsc2/dscrutils ...\u001b[0m\n",
      "INFO: DSC script exported to \u001b[32mdsc_result.html\u001b[0m\n",
      "INFO: Constructing DSC from \u001b[32msettings_error_v1.dsc\u001b[0m ...\n",
      "INFO: Building execution graph & running DSC ...\n",
      "DSC:  18%|███████                                | 2/11 [00:01<00:05,  1.60it/s]\n",
      "\u001b[91mERROR\u001b[0m: \u001b[91m[3808530b-4117-459c-990c-ab31d5074b42]: [normal_0]: \n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "script_6123501901101114663 in <module>\n",
      "      ## END code by DSC2\n",
      "      \n",
      "----> \"\"\", workdir = './', stderr = None, stdout = None)\n",
      "\n",
      "RuntimeError: Failed to execute commmand \u001b[0m\u001b[32mRscript --default-packages=datasets,methods,utils,stats,grDevices,graphics  /home/gaow/GIT/dsc2/vignettes/one_sample_location/.sos/normal_0_0_652e6bc3.R\u001b[0m\u001b[91m (ret=1, workdir=/home/gaow/GIT/dsc2/vignettes/one_sample_location)\n",
      "[49bb3658-fb20-4736-b8d4-1d9c2ee0c6f4]: [t_0]: \n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "script_-5770973451880312504 in <module>\n",
      "      ## END code by DSC2\n",
      "      \n",
      "----> \"\"\", workdir = './', stderr = None, stdout = None)\n",
      "\n",
      "RuntimeError: Failed to execute commmand \u001b[0m\u001b[32mRscript --default-packages=datasets,methods,utils,stats,grDevices,graphics  /home/gaow/GIT/dsc2/vignettes/one_sample_location/.sos/t_0_0_b8a69d4f.R\u001b[0m\u001b[91m (ret=1, workdir=/home/gaow/GIT/dsc2/vignettes/one_sample_location)\n",
      "[DSC]: 9 pending steps: DSC_0, a_mse, b_mse, c_mse, d_mse, a_mean, b_median, c_mean, d_median\u001b[0m\n",
      "\u001b[95mWARNING\u001b[0m: \u001b[95mIf needed, you can open \u001b[0m\u001b[32mdsc_result.scripts.html\u001b[0m\u001b[95m and use \u001b[0m\u001b[32mctrl-F\u001b[0m\u001b[95m to search by file names to trace back problematic chunks of code.\u001b[0m\n",
      "INFO: Elapsed time \u001b[32m5.065\u001b[0m seconds.\n"
     ]
    }
   ],
   "source": [
    "! dsc settings_error_v1.dsc --skip none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "The error message is a bit wordy but the part most relevant to debugging are highlighted in green color on your terminal. In this case multiple generated scripts have failed, but the cause is likely the same. You can try to resolve the problem starting from the last error message and see if the fix will help with other errors.\n",
    "\n",
    "You can also see that a file called `dsc_result.scripts.html` is generated. It bundles generated scripts from all module instances involved in the benchmark up to the point the errors occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Debug with the problematic script\n",
    "As prompted in the error message, let's try to execute `.sos/t_0_0_b8a69d4f.R`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in set.seed(seed) : object 'seed' not found\n",
      "Execution halted\n"
     ]
    }
   ],
   "source": [
    "! Rscript .sos/t_0_0_b8a69d4f.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Okey so what's going on? Let's take a look at this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">> .sos/t_0_0_b8a69d4f.R (337 B):</div>"
      ],
      "text/plain": [
       "\n",
       "> .sos/t_0_0_b8a69d4f.R (337 B):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## r script UUID: c218f56b48d262e5\n",
      "## BEGIN code by DSC2\n",
      "n <- 1000\n",
      "true_mean <- 0\n",
      "weed <- 1\n",
      "DSC_4AAF65D6_tic_pt <- proc.time()\n",
      "## END code by DSC2\n",
      "set.seed(seed)\n",
      "x=true_mean+rt(n,df=2)\n",
      "## BEGIN code by DSC2\n",
      "saveRDS(list(x=x, true_mean=true_mean, DSC_TIMER = proc.time() - DSC_4AAF65D6_tic_pt), 'dsc_result/t_1.rds')\n",
      "## END code by DSC2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%preview .sos/t_0_0_b8a69d4f.R -n -l -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "It looks like `set.seed()` looks for variable `seed`, which was not provided by DSC. We know from the [DSC script](https://github.com/stephenslab/dsc2/blob/master/vignettes/one_sample_location/settings_error_v1.dsc) that we had set `weed` not `seed`. So obviously there is a glitch on the interface which can be fixed by changing `weed` to `seed` in the DSC script.\n",
    "\n",
    "In practice when you identify problems that does not have an obvious fix such as this one, you should load the problematic script `.sos/t_0_0_b8a69d4f.R` to some interactive session, try to debug and fix the script from there (do not worry about changing this script), test until it works. Then you should have learned where the problem is, and you can apply what you've learned to patching DSC script or the original module code. *Fixing these generated scripts is not enough as they will be overwritten next time DSC runs*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buggy module script\n",
    "\n",
    "Now let's undermine the module code instead. We change `R/methods/mean.R` from:\n",
    "\n",
    "```r\n",
    "mean = mean(x)\n",
    "```\n",
    "\n",
    "to \n",
    "\n",
    "```r\n",
    "mean = 'meow'\n",
    "```\n",
    "\n",
    "As you can probably tell, this will not result an error for this module, but may impact downstream ones. So let's find it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DSC script exported to \u001b[32mdsc_result.html\u001b[0m\n",
      "INFO: Constructing DSC from \u001b[32msettings_error_v2.dsc\u001b[0m ...\n",
      "INFO: Building execution graph & running DSC ...\n",
      "DSC:  91%|██████████████████████████████████▌   | 10/11 [00:08<00:00,  1.22it/s]\n",
      "\u001b[91mERROR\u001b[0m: \u001b[91m[01278859-93de-4e0c-8126-f4af09cf28eb]: [mse_0]: \n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "script_4384414397566502935 in <module>\n",
      "      ## END code by DSC2\n",
      "      \n",
      "----> \"\"\", workdir = './', stderr = None, stdout = None)\n",
      "\n",
      "RuntimeError: Failed to execute commmand \u001b[0m\u001b[32mRscript --default-packages=datasets,methods,utils,stats,grDevices,graphics  /home/gaow/GIT/dsc2/vignettes/one_sample_location/.sos/mse_0_0_c3a61422.R\u001b[0m\u001b[91m (ret=1, workdir=/home/gaow/GIT/dsc2/vignettes/one_sample_location)\n",
      "[1c24f16d-7e75-4161-bbd6-97c3e35239bb]: [mse_0]: \n",
      "---------------------------------------------------------------------------\n",
      "RuntimeError                              Traceback (most recent call last)\n",
      "script_4384414397566502935 in <module>\n",
      "      ## END code by DSC2\n",
      "      \n",
      "----> \"\"\", workdir = './', stderr = None, stdout = None)\n",
      "\n",
      "RuntimeError: Failed to execute commmand \u001b[0m\u001b[32mRscript --default-packages=datasets,methods,utils,stats,grDevices,graphics  /home/gaow/GIT/dsc2/vignettes/one_sample_location/.sos/mse_0_0_93b09896.R\u001b[0m\u001b[91m (ret=1, workdir=/home/gaow/GIT/dsc2/vignettes/one_sample_location)\n",
      "[DSC]: 1 pending step: DSC_0\u001b[0m\n",
      "\u001b[95mWARNING\u001b[0m: \u001b[95mIf needed, you can open \u001b[0m\u001b[32mdsc_result.scripts.html\u001b[0m\u001b[95m and use \u001b[0m\u001b[32mctrl-F\u001b[0m\u001b[95m to search by file names to trace back problematic chunks of code.\u001b[0m\n",
      "INFO: Elapsed time \u001b[32m11.066\u001b[0m seconds.\n"
     ]
    }
   ],
   "source": [
    "! dsc settings_error_v2.dsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in mean_est - true_mean : non-numeric argument to binary operator\n",
      "Execution halted\n"
     ]
    }
   ],
   "source": [
    "! Rscript .sos/mse_0_0_93b09896.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we examine the code by adding a couple of `print` commands before the line in question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"meow\"\n",
      "[1] 0\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in mean_est - true_mean: non-numeric argument to binary operator\n",
     "output_type": "error",
     "traceback": [
      "Error in mean_est - true_mean: non-numeric argument to binary operator\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "## BEGIN code by DSC2\n",
    "DSC_1589D5E6 <- list()\n",
    "input.files <- c('dsc_result/t_1.rds','dsc_result/t_1_mean_1.rds')\n",
    "for (i in 1:length(input.files)) DSC_1589D5E6 <- dscrutils:::merge_lists(DSC_1589D5E6, readRDS(input.files[i]))\n",
    "mean_est <- DSC_1589D5E6$mean\n",
    "true_mean <- DSC_1589D5E6$true_mean\n",
    "DSC_1589D5E6_tic_pt <- proc.time()\n",
    "## END code by DSC2\n",
    "\n",
    "print(mean_est)\n",
    "print(true_mean)\n",
    "mse = (mean_est-true_mean)^2\n",
    "\n",
    "\n",
    "## BEGIN code by DSC2\n",
    "saveRDS(list(mse=mse, DSC_TIMER = proc.time() - DSC_1589D5E6_tic_pt), 'dsc_result/t_1_mean_1_mse_1.rds')\n",
    "## END code by DSC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `mean_est`, instead of being a number, is a string `meow`. Therefore the line `mse = (mean_est-true_mean)^2` is doomed to fail. We know from the DSC script that `mean_est` comes from an upstream module ensemble `estimate`, that somehow returned `meow` as output. We can also see from this script that the variable comes from one of `'dsc_result/t_1.rds','dsc_result/t_1_mean_1.rds'`. From our knowledge in the DSC script we know it should come from `'dsc_result/t_1_mean_1.rds'` the `mean` module. Therefore there is nothing we can do in the current script to fix the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Debugging with upstream scripts\n",
    "\n",
    "Now we want to find out what has produced the problematic `mean_est` variable. That is, we want to find the module instance that generated `'dsc_result/t_1_mean_1.rds'` from which `mean_est` is loaded. However the problematic script above did not tell us where this data comes from. This leads us to examine other scripts in the benchmark that leads to the error, in [`dsc_result.scripts.html`](dsc_result.scripts.html).\n",
    "\n",
    "You can open up [this file](dsc_result.scripts.html) in your web browser, and *search* (`ctrl-F`) for the phrase `dsc_result/t_1_mean_1.rds`. This leads you to the following: \n",
    "\n",
    "![debug-1](../img/debug-tips-1.png)\n",
    "\n",
    "Unsurprisingly, running these code by itself produces no error message -- this is expected because otherwise DSC would have failed at this stage. However we know from previous investigation that the output does not look right. For this example we can spot instantly that the `meow` string somehow &#128049; replaced the code for location parameter estimation; and we can fix it easily. In practice, one may need to load both this code chunk and the previous `.sos/mse_0_0_93b09896.R` to an interactive session, fix the code until `.sos/mse_0_0_93b09896.R` works, and apply the knowledge learned to the original module `R/method/mean.R`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Debug with `--target` and `--truncate`\n",
    "It is highly recommanded that these options be used to check the correctness of DSC benchmark as you develop them. Do not run the entire benchmark unless you have checked it bit by bit. `--truncate` will only run one instance from a module, thus enables running a fraction of DSC benchmark relatively quickly to ensure everthing is correct. Additionally it is suggested that a benchmark be executed module by module using `--target`: the next module or module ensemble is only attedmpted when there is no obvious problem with the previous module. For example for a DSC benchmark:\n",
    "\n",
    "```\n",
    "DSC:\n",
    "  define: \n",
    "      simulate: normal, t\n",
    "      estimate: median, mean\n",
    "  run: simulate * estimate * mse\n",
    "```\n",
    "When the benchmark is tested for the first time, one should at least run the following sequentially:\n",
    "\n",
    "```\n",
    "dcs file.dsc --target normal --truncate\n",
    "dcs file.dsc --target t --truncate\n",
    "dcs file.dsc --target \"normal * mean\" --truncate\n",
    "dcs file.dsc --target \"normal * median\" --truncate\n",
    "dcs file.dsc --target \"normal * median * mse\" --truncate\n",
    "```\n",
    "\n",
    "This will ensure all module are tested for at least one instance. Then you can run the benchmark knowing that the chances of errors has already been reduced.\n",
    "\n",
    "```\n",
    "dcs file.dsc \n",
    "```\n",
    "\n",
    "## Log files\n",
    "The run-time information are kept in greater detail in `*.log` file, when used with verbosity level greater than `2`. Though typically unnecessary, if you still cannot fix issues at this point it may help re-running benchmark with `-v 4` and look into the log file for more run-time information to help performing diagnostics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "celltoolbar": true,
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "SoS",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
