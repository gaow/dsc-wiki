---
title: "dsc_intro.rmd"
author: "Matthew Stephens"
date: "2/26/2018"
output: html_document
---

# First Course Explained

This is a continuation of the [First Course to DSC](First_Course.html). We elaborate on the design and syntax for DSC First Course example.

## Planning: module input/output and pipeline variables

As with any programming project, before writing a DSC file it is helpful to do some planning. We suggest starting by
identifying the *types of module* and the *quantities that are going to be passed from module to module*. In DSC we refer to quantities that are passed from module to module as "pipeline variables". Pipeline variables should be given an informative name which must begin with a `$`. (Note: variable names in DSC cannot contain a `.`, because this is reserved for another use; we suggest using `_` instead.)

Here we follow the simple three-step
`simulate`-`analyze`-`score` design mentioned
above. We thus have three different types of module:

+ a `simulate` module will output a vector of simulated data (`$data`),  and the value of the true distribution mean used to simulate it (`$true_mean`). 
+ an `analyze` module will input `$data` and output an estimate (`$est_mean`) of the true distribution mean.
+ a `score` module will input `$est_mean` and `$true_mean` and output a measure of the error (`$error`).

### Notes on pipeline variables

Some details of this plan may seem unclear until
you better understand the way DSC works. However the following notes about pipeline variables may help understanding.

1. The pipeline variables output by a module are exactly the
parts of the module output that are saved (in a file) for future use. So `$error` is here considered a pipeline variable because we want it saved at the end of the pipeline. 

2. The pipeline variables are the only way that modules can communicate with one another. So if a module requires access to a piece of information generated by a previous module then this must be a pipeline variable. For example, a `score` module  naturally requires access to the true mean used to generate the data, so here this is output, as a pipeline variable, from a `simulate` module. 

If you are familiar with
file-based workflows (e.g. make or Snakemake) then 
it may help to think of the pipeline variables as files (which is indeed how they are implemented).


<!-- Here the pipeline variables are: -->

<!-- - `$data`: a vector of data sampled from a distribution -->
<!-- - `$true_mean`: the true mean of the distribution from which the data were sampled -->
<!-- - `$est_mean`: an estimate of the  mean of the distribution (each method will output some such estimate) -->
<!-- - `$error`: a measure of the error in the estimate compared with the truth -->

<!-- We might summarize this schematically as: -->
<!-- (maybe a picture here) -->

<!-- + `simulate: . -> $data, $true_mean` -->
<!-- + `analyze: $data -> $est_mean` -->
<!-- + `score: $est_mean,$true_mean -> $error` -->


## A `simulate` module

Suppose we have the following one-line of R code in a file `normal.R`:

```x = rnorm(n,0,1)```

This code generates a vector containing `n` random sammples from an $N(0,1)$ distribution, and assigns it to a variable called `x`. We will refer to code like this as a "script", and variables used within the script as "script variables".
So here `x` and `n` are script variables.

Here we will use this script to specify a DSC module (a `simulate` module). To do this we need to tell DSC four things:

- a name for the module (here `normal`) 
- the name of the file containing the script (`normal.R`) 
- what value to use for the script variable `n` (let's say 100 for now)
- how to determine the values of the pipeline variables `$data` and `$true_mean` after running this code. Here we want `$data` to take the value of the script variable `x`, and `$true_mean` is 0.

Here is all this information in DSC syntax:
```
normal: normal.R
  n: 100
  $data: x
  $true_mean: 0
```

It is important to ensure the variable names match between R script and DSC files. The DSC code block above interacts with `normal.R`, a one-liner R script `x = rnorm(n,0,1)`, which uses parameters `n` on the right hand side to produce `x` on the left hand side, consistent with input `n: 100` and output `$data: x` specified for DSC module `normal`.

## Another `simulate` module

Suppose we have the following script in a file `t.R`:

```x = 3+rt(n,df)```

to generate `n` observations from a t distribution with mean 3 and `df` degrees of freedom.

We can use this to specify another `simulate` module called `t`.
Here is the DSC syntax:
```
t: t.R
  n: 100
  df: 2
  $data: x
  $true_mean: 3
```


## Two `analyze` module

Similarly we can create analyze modules. Recall we will 
have one module (which we will call `mean`) that estimates the distribution mean by the sample mean; and another module (`median`) to  estimate the distribution mean by the sample median.

Supposing the files `mean.R` and `median.R` contain the scripts
```
y = mean(x)
```
and
```
y = median(x)
```
respectively, we can define the modules in the DSC file:
```
mean: mean.R
  x: $data
  $est_mean: y
  
median: median.R
  x: $data
  $est_mean: y
```

This syntax tells DSC two key things: 

1. before running the script in `mean.R` (or `median.R`) it should set the script variable `x` to the value of the pipeline variable `$data`; and 
2. after running the script in `mean.R` (or `median.R`) it should set the value of the pipeline variable `$est_mean` to the value of the script variable `y`.

Notice how we use DSC 
to pass information from one script to another (through the use of modules and pipeline variables). 


## Two `score` modules

Finally we create two `score` modules, one based on squared error (`sq_err`) and one based on absolute error (`abs_err`).
Suppose the files `sq.R` and `abs.R` contain the scripts
```
e = (a-b)^2
```
and
```
e = abs(a-b)
```
respectively. Then we can define modules:
```
sq_err: sq.R
  a: $est_mean
  b: $true_mean
  $error: e
 
abs_err: abs.R
  a: $est_mean
  b: $true_mean
  $error: e 
```
  
## Defining groups and pipelines

The final stage is to tell DSC how to combine these
six modules into pipelines. We do this by
first defining the "groups" of similar modules, and then
defining pipelines in terms of these groups. 

```
DSC:
    define:
      simulate: normal, t
      analyze: mean, median
      score: abs_err, sq_err
    run: simulate * analyze * score
    exec_path: R
    output: dsc_result
```

Here:

- `DSC` is a keyword to indicate that here we are defining groups and pipelines (not a module definition).
- `define` is a keyword to indicate we are defining groups
(here `simulate`, `analyze` and `score`).
- `run` is a keyword to indicate that we are defining the pipelines to be run. The `A * B` notation means to create all possible sequences of modules from groups `A` and `B`. That is, all sequences of the form `a`-`b` where `a` is a module in group `A` and `b` is a module in a group `B`.
- `exec_path` tells DSC where to look for the script files
- `output` tells DSC where to save results

The `DSC::run` property reflects our `simulate`-`analyze`-`score` structure, a typical DSC setup where `normal` and `t` create *simulate* under various settings, `mean` and `median` are both methods to *analyze*, and `sq_err` and `abs_err` are *score*s that evaluate for performance. Therefore module groups `simulate`, `analyze` and `score` are created using `DSC::define` and are used to build pipelines (`*` operator) of combinations of modules.
